{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2066c38-fac4-4a0a-8147-fa9b5567f866",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import torch.optim.lr_scheduler as lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34659a4c-14a5-40f6-ab9a-96cb7b6a57b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06795b30-5281-4be4-9136-461b436425e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path = r\"D:\\Machine Learning\\weather_prediction\\2023_weather_conditions_df.xlsx\"\n",
    "\n",
    "df = pd.read_excel(df_path, engine = \"openpyxl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2040195-40b5-4686-98f6-4d3ad177d775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Homérséklet</th>\n",
       "      <th>Páratartalom</th>\n",
       "      <th>Légnyomás</th>\n",
       "      <th>month_sin</th>\n",
       "      <th>month_cos</th>\n",
       "      <th>day_sin</th>\n",
       "      <th>day_cos</th>\n",
       "      <th>idokulonbseg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.6</td>\n",
       "      <td>82</td>\n",
       "      <td>1021.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.207912</td>\n",
       "      <td>0.207912</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.4</td>\n",
       "      <td>81</td>\n",
       "      <td>1020.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.207912</td>\n",
       "      <td>0.207912</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.3</td>\n",
       "      <td>81</td>\n",
       "      <td>1020.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.207912</td>\n",
       "      <td>0.207912</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.1</td>\n",
       "      <td>86</td>\n",
       "      <td>1020.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.207912</td>\n",
       "      <td>0.207912</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.9</td>\n",
       "      <td>86</td>\n",
       "      <td>1020.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.207912</td>\n",
       "      <td>0.207912</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Homérséklet  Páratartalom  Légnyomás  month_sin  month_cos   day_sin  \\\n",
       "0          6.6            82     1021.3        0.5        0.5  0.207912   \n",
       "1          6.4            81     1020.7        0.5        0.5  0.207912   \n",
       "2          6.3            81     1020.5        0.5        0.5  0.207912   \n",
       "3          6.1            86     1020.4        0.5        0.5  0.207912   \n",
       "4          5.9            86     1020.5        0.5        0.5  0.207912   \n",
       "\n",
       "    day_cos  idokulonbseg  \n",
       "0  0.207912            15  \n",
       "1  0.207912            16  \n",
       "2  0.207912            19  \n",
       "3  0.207912            15  \n",
       "4  0.207912            15  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef344d88-7fa6-45d7-a80c-3276041c6cba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64509, 8)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69636fd8-849b-47a9-8dc6-cc6fa65141e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.17368421, 0.775     , 0.58230088, ..., 0.60452846, 0.60452846,\n",
       "        0.0400534 ],\n",
       "       [0.16842105, 0.7625    , 0.57168142, ..., 0.60452846, 0.60452846,\n",
       "        0.04072096],\n",
       "       [0.16578947, 0.7625    , 0.56814159, ..., 0.60452846, 0.60452846,\n",
       "        0.04272363],\n",
       "       ...,\n",
       "       [0.22631579, 0.6625    , 0.43539823, ..., 0.60452846, 0.60452846,\n",
       "        0.04339119],\n",
       "       [0.22105263, 0.675     , 0.43362832, ..., 0.60452846, 0.60452846,\n",
       "        0.0400534 ],\n",
       "       [0.21315789, 0.675     , 0.43539823, ..., 0.60452846, 0.60452846,\n",
       "        0.0400534 ]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "scaled_df = scaler.fit_transform(df)\n",
    "\n",
    "scaled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b4f51523-e436-4fdf-a5cc-64aef64a1eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeatherDataset(Dataset):\n",
    "    def __init__(self, x_data, y_data, time_diff_data):\n",
    "        self.x_data = x_data\n",
    "        self.y_data = y_data\n",
    "        self.time_diff_data = time_diff_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x_data[idx], self.y_data[idx], self.time_diff_data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba980566-aa95-4c3a-8fde-f9543b5c2052",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, input_length, output_length):\n",
    "\n",
    "    sequences_x = []\n",
    "    sequences_y = []\n",
    "    sequences_time_diff = []\n",
    "    for i in range(len(data)-input_length-output_length+1):\n",
    "        sequences_x.append(data[i:i+input_length])\n",
    "        sequences_y.append(data[i+input_length:i+input_length+output_length,0]) #It only should use the first column\n",
    "        sequences_time_diff.append(data[i+input_length:i+input_length+output_length,-1]) #It only should use the last column\n",
    "\n",
    "    return np.array(sequences_x), np.array(sequences_y), np.array(sequences_time_diff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa896f7f-337e-443d-ad96-b52979888765",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_length = 700\n",
    "output_length = 300\n",
    "\n",
    "sequences_x, sequences_y, sequences_time_diff = create_sequences(scaled_df, input_length, output_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6cb9a4b6-650e-4d7a-9adc-c3f932601704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((63510, 700, 8), (63510, 300), (63510, 300))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences_x.shape, sequences_y.shape, sequences_time_diff.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4a931d44-234c-46d4-861f-a111c9c46281",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_weather(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_size, num_layers, seq_length, output_length):\n",
    "        super(LSTM_weather, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.seq_length = seq_length\n",
    "        self.output_length = output_length\n",
    "\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_size, num_layers, batch_first = True)\n",
    "        self.fc_1 = nn.Linear(hidden_size, 128)\n",
    "        self.fc_2 = nn.Linear(128, 1)\n",
    "        self.fc_time = nn.Linear(128, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        h_0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c_0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "\n",
    "        output, (hn, cn) = self.lstm(x, (h_0, c_0))\n",
    "\n",
    "        out = output[:, -self.output_length:, :]\n",
    "        out = self.relu(out)\n",
    "        out = self.fc_1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out_value = self.fc_2(out)\n",
    "        out_time = self.fc_time(out)\n",
    "\n",
    "\n",
    "\n",
    "        return out_value, out_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "396017a8-d436-4911-9427-27fbbba35aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_split(sequences_x, sequences_y, sequences_time_diff, val_percentage):\n",
    "    val_size = int(val_percentage*len(sequences_x)/100)\n",
    "    val_x, train_x = sequences_x[:val_size], sequences_x[val_size:]\n",
    "    val_y, train_y = sequences_y[:val_size], sequences_y[val_size:]\n",
    "    val_time_diff, train_time_diff = sequences_time_diff[:val_size], sequences_time_diff[val_size:]\n",
    "\n",
    "    return train_x, val_x, train_y,  val_y, train_time_diff, val_time_diff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "356c0450-1e25-4ab9-b6f8-b55992552c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val, train_time_diff, val_time_diff = train_val_split(sequences_x, sequences_y, sequences_time_diff, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "235938c7-68a3-4932-a1c9-f2120bfe583e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = WeatherDataset(torch.tensor(x_train, dtype = torch.float32).to(device), torch.tensor(y_train, dtype = torch.float32).to(device), torch.tensor(train_time_diff, dtype = torch.float32).to(device))\n",
    "val_dataset = WeatherDataset(torch.tensor(x_val, dtype = torch.float32).to(device), torch.tensor(y_val, dtype = torch.float32).to(device), torch.tensor(val_time_diff, dtype = torch.float32).to(device))\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle = False, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size = batch_size, shuffle = False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "68f52941-3588-480e-9cf7-02ec0152c539",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 8\n",
    "hidden_size = 512\n",
    "num_layers = 2\n",
    "seq_length = 700\n",
    "output_length = 300\n",
    "\n",
    "model = LSTM_weather(input_dim, hidden_size, num_layers, seq_length, output_length).to(device)\n",
    "\n",
    "criterion_value = nn.MSELoss()\n",
    "criterion_time = nn.MSELoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.005, weight_decay=1e-5)\n",
    "scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d58e0359-dcb4-4de5-81ed-9ed75125913d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plotting_loss(epochs, train_loss, val_loss, train_loss_value, val_loss_value):\n",
    "\n",
    "  plt.subplot(2,1,1)\n",
    "  plt.plot(epochs, train_loss, color = 'b', label = 'Training Loss')\n",
    "  plt.plot(epochs, val_loss, color = 'g', label = 'Validation Loss')\n",
    "  plt.xlabel(\"Epochs\")\n",
    "  plt.ylabel(\"Loss\")\n",
    "  plt.title('Summed up loss over Epochs')\n",
    "  plt.legend()\n",
    "  plt.grid(True)\n",
    "\n",
    "  plt.subplot(2,1,2)\n",
    "  plt.plot(epochs, train_loss_value, color = 'b', label = 'Training Loss')\n",
    "  plt.plot(epochs, val_loss_value, color = 'g', label = 'Validation Loss')\n",
    "  plt.xlabel(\"Epochs\")\n",
    "  plt.ylabel(\"Loss\")\n",
    "  plt.title('Value loss over Epochs')\n",
    "  plt.legend()\n",
    "  plt.grid(True)\n",
    "\n",
    "  plt.tight_layout()\n",
    "  plt.show()\n",
    "  plt.savefig('D:/Machine Learning/weather_prediction/best_weights_model/second_model_loss_epoch_fig.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcca6cf0-dbf2-42e3-aa1a-2a65a6bf03e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 120\n",
    "\n",
    "best_loss1 = float('inf')\n",
    "best_loss2 = float('inf')\n",
    "\n",
    "\n",
    "train_loss_value = []\n",
    "val_loss_value = []\n",
    "val_loss = []\n",
    "train_loss = []\n",
    "epochs = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epochs.append(epoch+1)\n",
    "\n",
    "\n",
    "    train_loss_value1 = 0\n",
    "    val_loss_value1 = 0\n",
    "    train_loss1 = 0\n",
    "    val_loss1 = 0\n",
    "\n",
    "    model.train()\n",
    "    for x_batch, y_batch, time_diff_batch in train_loader:\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output_value, output_time_diff = model(x_batch)\n",
    "\n",
    "        loss1 = criterion_value(output_value.squeeze(-1), y_batch)\n",
    "        loss2 = criterion_time(output_time_diff.squeeze(-1), time_diff_batch)\n",
    "\n",
    "        loss = loss1 + loss2\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss1 += loss.item()\n",
    "        train_loss_value1 += loss1.item()\n",
    "\n",
    "    train_loss1 /= len(train_loader) #taking the average\n",
    "    train_loss.append(train_loss1)\n",
    "\n",
    "    train_loss_value1 /= len(train_loader) #taking the average\n",
    "    train_loss_value.append(train_loss_value1)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x_val_batch, y_val_batch, time_diff_val_batch in val_loader:\n",
    "\n",
    "            output_value_val, output_time_diff_val = model(x_val_batch)\n",
    "\n",
    "            loss_value_val = criterion_value(output_value_val.squeeze(-1), y_val_batch)\n",
    "            loss_time_val = criterion_time(output_time_diff.squeeze(-1), time_diff_val_batch)\n",
    "\n",
    "            loss_val = loss_value_val + loss_time_val\n",
    "            val_loss1 += loss_val.item()\n",
    "            val_loss_value1 += loss_value_val.item()\n",
    "\n",
    "    val_loss1 /= len(val_loader) #taking the average\n",
    "    val_loss.append(val_loss1)\n",
    "\n",
    "    val_loss_value1 /= len(val_loader) #taking the average\n",
    "    val_loss_value.append(val_loss_value1)\n",
    "\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    print(f'Epoch: {epoch+1}, Training loss: {train_loss1}, Validation loss: {val_loss1}')\n",
    "\n",
    "    if val_loss1 < best_loss1 or val_loss_value1 < best_loss2:\n",
    "      if val_loss1 < best_loss1:\n",
    "        best_loss1 = val_loss1\n",
    "      if val_loss_value1 < best_loss2:\n",
    "        best_loss2 = val_loss_value1\n",
    "\n",
    "      torch.save(model.state_dict(), f'D:/Machine Learning/weather_prediction/best_weights_model/second_try_model_weights_{epoch+1}.pth')\n",
    "\n",
    "best_epoch1 = val_loss.index(max(val_loss)) + 1\n",
    "best_epoch2 = val_loss_value.index(max(val_loss_value)) + 1\n",
    "\n",
    "print(f\"The best performing epoch by summed up loss: {best_epoch1}\")\n",
    "print(f\"The best performing epoch by value loss: {best_epoch2}\")\n",
    "\n",
    "\n",
    "plotting_loss(epochs, train_loss, val_loss, train_loss_value, val_loss_value)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
